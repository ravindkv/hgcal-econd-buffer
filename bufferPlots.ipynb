{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"%s/hgcalEnv/lib/python3.6/site-packages/\"%os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of number of link that are assigned\n",
    "linkSummary = pd.read_csv('geomInfo/ModuleLinkSummary.csv')\n",
    "\n",
    "# six cassettes are put together to form one layer. Currently, we look at only 0th cassete of a few layers (5,7,9)\n",
    "linkSummary = linkSummary[(linkSummary.Cassette==0) & (linkSummary.Layer>=5) & (linkSummary.Layer<=9)]\n",
    "\n",
    "# The (ModU, modV) is the (U, V) coordinate of a module (=wafer=econ) within a layer\n",
    "linkSummary.set_index(['Layer','ModU','ModV'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data from csv files.  This is used to extract average data sizes\n",
    "#daq_Data = pd.concat([pd.read_csv(f'Data/ttbar_copy_new.csv') for i in range(16)])\n",
    "daq_Data = pd.read_csv('dataZS_merged.csv')\n",
    "'''\n",
    "The daq_Data consist of the entries after applying ZS corresponding to different cells \n",
    "(a layer has many wafers, a wafer has many cells). The description about the each of columns\n",
    "(c1): It is the index of df\n",
    "(c2 = entry): those events which passed the ZS\n",
    "(c3 = layer): layer number (from 5 to 9)\n",
    "(c4 = waferu): U coordinate of the wafer\n",
    "(c5 = waferv): V coordinate of the wafer\n",
    "\n",
    "(c6 = HDM): high density module: One of the 8-inch wafers/modules with 432 cells \n",
    "(compared to the LDM, or low-density module, which has 192 cells)\n",
    "the type 0 are 120 micron thick and HDM and closest to beam pipe,\n",
    "type 1 is 200 microns thick LDM modules, and a little further out\n",
    "type 2 are 300 micron LDM modules, and furthest from beam pipe in eta\n",
    "If HDM is True then it correspond to type 0 else 1 or 2\n",
    "\n",
    "(c7 = occ): Occupancy: Each wafer has 3-6 eLink, each eLink has up to 37 channels, \n",
    "weâ€™ve applied the zero suppression, so any channel below the threshold is removed, \n",
    "so the count is just counting how many cells on a given eLink on a given wafer pass the ZS\n",
    "\n",
    "(c8 = eRxPacket_Words): It is the size of the packet in terms of number of words (1 word is of 32 bit).\n",
    "It is calculated as int(Bits/32+1) + 2, where Bits = 16  + 8* (charge_BX1 + toa_BX2)\n",
    "\n",
    "(c9  = NonEmptyLinks): We have total 6 (12) eLinks for HDM(LDM). \n",
    "\n",
    "(c10 = EmptyLinks): The rest eLinks\n",
    "\n",
    "(c11 = TotalWords): evt_headerWords (=2) + eRxPacket_Words + EmptyLinks + evt_trailerWords (=2)\n",
    "\n",
    "''' \n",
    "daq_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of wedges, and assign x and y positions for drawing maps\n",
    "wedges = daq_Data.groupby(['layer','waferu','waferv']).any()[['HDM']].reset_index()\n",
    "wedges['y'] = wedges.waferv\n",
    "wedges['x'] = 0\n",
    "#QQQQ: why 2+v-2*u?\n",
    "wedges.loc[:,'x'] = (2+wedges.y-2*wedges.waferu)\n",
    "#QQQQ: why rescale y and x?\n",
    "wedges.y *= 1.5\n",
    "wedges.x *= -3**.5/2\n",
    "wedges.set_index(['layer','waferu','waferv'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to look through output logs of condor jobs to extract and accumulate the results across several runs\n",
    "# if you just ran interactivel, need to just get the info on the overflows, max size, etc into a dataframe.\n",
    "\n",
    "def getDF(inputDF, LogName=None,Nstart=0,N=100):\n",
    "    #QQQQ: Why mean?\n",
    "    fullData = inputDF.groupby(['layer','waferu','waferv']).mean()\n",
    "    \n",
    "    #linkSummary has only 153 rows which means the last 10 rows will be assigned Nan. \n",
    "    #QQQQ: Why linkSummary has only 153 rows?\n",
    "    fullData['eTx_assigned'] = linkSummary.ECOND_eTX\n",
    "    \n",
    "    #Replace Nan by 1\n",
    "    fullData.eTx_assigned = fullData.eTx_assigned.fillna(1).astype(int)\n",
    "    \n",
    "    #The numpy.ceil() is a mathematical function that returns the ceil of the elements of array. \n",
    "    #The ceil of the scalar x is the smallest integer i, such that i >= x\n",
    "    #QQQQ: why divide by 53.3333? One eTx can process 53.3333 Words of data?\n",
    "    fullData['eTx_30percent'] = np.ceil((fullData.TotalWords/53.3333)*1.3).astype(int)\n",
    "    fullData['eTx_Mean'] = np.ceil((fullData.TotalWords/53.3333))\n",
    "    '''\n",
    "    Every condor output has information for 6 econs (they have different # eLinks)\n",
    "    We collect information from ALL condor outputs for ALL econs in a 2D (163,6) array\n",
    "\n",
    "    overflows: An econ with few number of eLink is overflow for a few thousands times in \n",
    "    few million BX which means for few billion BXs (many condor outputs) the overflows should be added\n",
    "\n",
    "    maxSize: Among all condor outouts, it is the maximum buffer size. Which means it is NOT additive\n",
    "\n",
    "    L1As issued: How many times an L1A is issued for a given number of BXs. Which means it is additive\n",
    "\n",
    "    '''\n",
    "    if not LogName is None:\n",
    "        data_overflow = []\n",
    "        data_maxSize = []\n",
    "        L1As_issued=0\n",
    "        bHist = []\n",
    "        #Get the 0th element of the list from 0th condor file\n",
    "        fileName = f'condor_buffer/tmpSub/log/{LogName}_{Nstart}.stdout'\n",
    "        with open(fileName,'r') as _file:\n",
    "            # we loop over all lines of the condor output and extract\n",
    "            for line in _file:\n",
    "                if 'overflows= ' in line:\n",
    "                    #overflows= [...]\n",
    "                    data_overflow.append(eval(line[10:]))\n",
    "                if 'maxSize= ' in line:\n",
    "                    #maxSize= [...]\n",
    "                    data_maxSize.append(eval(line[8:]))\n",
    "                if 'L1As issued' in line:\n",
    "                    #749401 L1As issued\n",
    "                    L1As_issued += int(line.split()[0])\n",
    "                if 'sizeHist= ' in line:\n",
    "                    bHist.append(eval(line[9:]))\n",
    "        #2D array            \n",
    "        data_overflow=np.array(data_overflow)\n",
    "        data_maxSize=np.array(data_maxSize)\n",
    "        buff_Hist = np.array(bHist)\n",
    "\n",
    "        for i_file in range(Nstart+1,Nstart+N):\n",
    "            fileName = f'condor_buffer/tmpSub/log/{LogName}_{i_file}.stdout'\n",
    "            bHist = []\n",
    "            with open(fileName,'r') as _file:\n",
    "                for line in _file:\n",
    "                    if 'eTx' in line:\n",
    "                        #1 eTx\n",
    "                        i = int(line.split()[0])-1\n",
    "                    if 'overflows= ' in line:\n",
    "                        overflow=np.array(eval(line[10:]))\n",
    "                        overflow[overflow<0] = 99999999\n",
    "                        data_overflow[i] += overflow\n",
    "                    if 'maxSize= ' in line:\n",
    "                        maxSize=np.array(eval(line[8:]))\n",
    "                        data_maxSize[i] = np.maximum(data_maxSize[i], maxSize)\n",
    "                    if 'L1As issued' in line:\n",
    "                        L1As_issued += int(line.split()[0])\n",
    "                    if 'sizeHist= ' in line:\n",
    "                        bHist.append(eval(line[9:]))\n",
    "            buff_Hist += np.array(bHist)\n",
    "        \n",
    "        '''\n",
    "        The idea is to check how many eLinks are needed for a given wafer in order to avoid overflow.\n",
    "        For example, the wafer closer to beam axis need more eLinks and vice versa. In this way we can\n",
    "        efficiantly allocate different number of eLinks to different wafers\n",
    "        '''\n",
    "        #transpose (163 col, 6 rows) to (6 cols, 163 rows)\n",
    "        #In every row look at zero (True==0) and non-zero entries\n",
    "        #Multiply the respective entry by array([1, 2, 3, 4, 5, 6])\n",
    "        print(data_overflow)\n",
    "        x = ((data_overflow.transpose()==0)*np.arange(1,7))\n",
    "\n",
    "        #change all zero entries to 99 (we can choose any large value)\n",
    "        x[x==0]=99\n",
    "        \n",
    "        #for every row, get the minimum value (out of 6 econs, pick the one which has minimum eLink)\n",
    "        minLinks = x.min(axis=1)\n",
    "        fullData['min_eTx'] = minLinks\n",
    "        nLinks = minLinks\n",
    "        \n",
    "        #Get the maximum size of the buffer of the corresponding econ with minLinks\n",
    "        maxSize = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize'] = maxSize    \n",
    "\n",
    "        nLinks = fullData.eTx_Mean.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][int(nLinks[i])-1])\n",
    "            overflows.append(data_overflow.transpose()[i][int(nLinks[i])-1])\n",
    "        fullData['maxSize_Mean'] = maxSize\n",
    "        fullData['overflows_Mean'] = overflows\n",
    "\n",
    "        \n",
    "        nLinks = fullData.eTx_assigned.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_assigned'] = maxSize\n",
    "        fullData['overflows_assigned'] = overflows\n",
    "        \n",
    "\n",
    "        nLinks = fullData.eTx_30percent.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_30percent'] = maxSize\n",
    "        fullData['overflows_30percent'] = overflows\n",
    "        print(\"fullData = \", fullData)\n",
    "        #print(\"L1As_issued = \", L1As_issued)\n",
    "        #print(\"data_overflow = \", data_overflow)\n",
    "        #print(\"data_maxSize = \", data_maxSize)\n",
    "    #return fullData, L1As_issued, data_overflow, data_maxSize, buff_Hist\n",
    "    #print(\"buff_Hist\", buff_Hist)\n",
    "    return fullData, L1As_issued, buff_Hist, data_overflow, data_maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fullData,L1As, buffHist, OF, MS = getDF(daq_Data,LogName='bufferSim__34676729',Nstart=0,N=2)\n",
    "fullData,L1As, buffHist, OF, MS = getDF(daq_Data,LogName='bufferSim__73944536',Nstart=0,N=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = [\"c\", \"b\", \"g\", \"r\",\"m\",\"y\"]\n",
    "xArray = []\n",
    "for i in range(1536*2):\n",
    "    xArray.append(i)\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "count = 1\n",
    "plt.subplots(figsize=(15, 10))\n",
    "#for h in range(len(buffHist)):\n",
    "for h in range(15):\n",
    "    #print(count)\n",
    "    plt.subplot(3, 5, count)\n",
    "    for eTx in range(len(buffHist)):\n",
    "        #plt.plot( xArray, buffHist[eTx][h], label=\"eTx=%i\"%(eTx+1))\n",
    "        plt.hist(xArray, bins=50, weights=buffHist[eTx][h], edgecolor=colList[eTx], label=\"eTx=%i\"%(eTx+1), histtype='step', linewidth=2)\n",
    "        plt.title(\"wafer=%s\"%str(wedges.index[h]))\n",
    "        #plt.xlabel(\"Buffer size (32-bit words)\", size=14)\n",
    "        #plt.xlabel(\"Buffer size\", size=14)\n",
    "        plt.legend(loc='upper center')\n",
    "        plt.yscale('log')\n",
    "    count+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETx = np.array(fullData.eTx_Mean.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_30percent.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx+30% from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_assigned.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"eTx assigned from HGCal baseline\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETx = np.array(fullData.eTx_Mean.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_30percent.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx+30% from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_assigned.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(OF.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(OF.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(OF.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"Number of times buffer has Overflown\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"eTx assigned from HGCal baseline\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETx = np.array(fullData.eTx_Mean.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(MS.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(MS.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(MS.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"max buffer size (32-bit words)\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_30percent.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(MS.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(MS.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(MS.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"max buffer size (32-bit words)\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"#eTx+30% from mean data\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "ETx = np.array(fullData.eTx_assigned.tolist())\n",
    "l1_ETx = ETx[0:53]\n",
    "l2_ETx = ETx[53:53+55]\n",
    "l3_ETx = ETx[53+55:53+55+55]\n",
    "l1_overflow = []\n",
    "l2_overflow = []\n",
    "l3_overflow = []\n",
    "for i in np.arange(len(l1_ETx)):\n",
    "    eTx = int(l1_ETx[i])\n",
    "    l1_overflow.append(MS.transpose()[i][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l2_ETx)):\n",
    "    eTx = int(l2_ETx[i])\n",
    "    l2_overflow.append(MS.transpose()[i+53][eTx-1])\n",
    "\n",
    "for i in np.arange(len(l3_ETx)):\n",
    "    eTx = int(l3_ETx[i])\n",
    "    l3_overflow.append(MS.transpose()[i+53+55][eTx-1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(l1_overflow, bins=70, alpha=0.5, label=\"layer = 5 (53 wafers)\", histtype='step', linewidth=3, edgecolor='r')\n",
    "plt.hist(l2_overflow, bins=70, alpha=0.5, label=\"layer = 7 (55 wafers)\", histtype='step', linewidth=3, edgecolor='g')\n",
    "plt.hist(l3_overflow, bins=70, alpha=0.5, label=\"layer = 9 (55 wafers)\", histtype='step', linewidth=3, edgecolor='b')\n",
    "plt.xlabel(\"max buffer size (32-bit words)\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.title(\"eTx assigned from HGCal baseline\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_eTx = [4, 4, 1]\n",
    "l1_wafer = [3, 4, 51]\n",
    "l1_eTx_wafer = [[4, 3],[4, 4], [1, 51]]\n",
    "#l1_eTx_wafer = [[1,51]]\n",
    "\n",
    "xArray = []\n",
    "for i in range(1536*2):\n",
    "    xArray.append(i)\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "#count = 1\n",
    "plt.subplots(figsize=(5, 5))\n",
    "#for h in range(len(buffHist)):\n",
    "for (eTx, h) in l1_eTx_wafer:\n",
    "    #print(eTx,h)\n",
    "    #plt.plot( xArray, buffHist[eTx][h], label=\"eTx=%i\"%(eTx+1))\n",
    "    lab = \"wafer = %s, eTx = %i\"%(str(wedges.index[h]), eTx)\n",
    "    #lab = \"eTx = %s, wafer = %i\"%(eTx,h)\n",
    "    plt.hist(xArray, bins=100, weights=buffHist[eTx-1][h], label=lab, histtype='step', linewidth=2)\n",
    "    #plt.plot(xArray, buffHist[eTx-1][h])\n",
    "    #plt.title(\"wafer=%s\"%str(wedges.index[h]))\n",
    "    plt.xlabel(\"Buffer size (32-bit words)\", size=14)\n",
    "    plt.ylabel(\"BX\", size=14)\n",
    "    #plt.xlabel(\"Buffer size\", size=14)\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.yscale('log')\n",
    "    #count+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(OF[0], bins=70, alpha=0.5, label=\"1 eTx\", fill=False, linewidth=3, edgecolor='c',range=[0.0, 0.7e7])\n",
    "plt.hist(OF[1], bins=70, alpha=0.5, label=\"2 eTx\", fill=False, linewidth=3, edgecolor='b',range=[0.0, 0.7e7])\n",
    "plt.hist(OF[2], bins=70, alpha=0.5, label=\"3 eTx\", fill=False, linewidth=3, edgecolor='g',range=[0.0, 0.7e7])\n",
    "plt.hist(OF[3], bins=70, alpha=0.5, label=\"4 eTx\", fill=False, linewidth=3, edgecolor='r',range=[0.0, 0.7e7])\n",
    "plt.hist(OF[4], bins=70, alpha=0.5, label=\"5 eTx\", fill=False, linewidth=3, edgecolor='m',range=[0.0, 0.7e7])\n",
    "plt.hist(OF[5], bins=70, alpha=0.5, label=\"6 eTx\", fill=False, linewidth=3, edgecolor='y',range=[0.0, 0.7e7])\n",
    "plt.xlabel(\"Overflows\", size=14)\n",
    "plt.ylabel(\"Number of Wafers\", size=14)\n",
    "plt.yscale('log')\n",
    "plt.title(\"Overflows for different numbers of eTx\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaly of the labels for different types of plots\n",
    "Labels ={'occ':{'Title':'Layer %i',\n",
    "                'colorLabel':'Average cell occupancy above zero suppression',\n",
    "                'nDec':1,\n",
    "                'zMax':260},\n",
    "         'TotalWords':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Average data size (32b words) after L1A',\n",
    "                      'nDec':1,\n",
    "                      'zMax':200},\n",
    "         'EmptyLinks':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Average # of empty eRx packets',\n",
    "                      'nDec':1,\n",
    "                      'zMax':6},\n",
    "         'min_eTx':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Minimum number of eTx with 0 overflows',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'maxSize':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Max buffer size (32b words), with 0 overflows',\n",
    "                      'nDec':0,\n",
    "                      'zMax':3300},\n",
    "         'eTx_Mean':{'Title':'Layer %i',\n",
    "                      'colorLabel':'#eTx from mean data',\n",
    "                      'nDec':2,\n",
    "                      'zMax':6},\n",
    "         'eTx_30percent':{'Title':'Layer %i',\n",
    "                      'colorLabel':'#eTx+30% from mean data',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'eTx_assigned':{'Title':'Layer %i',\n",
    "                      'colorLabel':'#eTx assigned from HGCal baseline',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'maxSize_Mean':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Max buffer size for #eTx from mean data',\n",
    "                      'nDec':0,\n",
    "                      'zMax':3300},\n",
    "         'maxSize_30percent':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Max buffer size for #eTx+30% from mean data',\n",
    "                      'nDec':0,\n",
    "                      'zMax':3300},\n",
    "         'maxSize_assigned':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Max buffer size for #eTx assigned from HGCal baseline',\n",
    "                      'nDec':0,\n",
    "                      'zMax':3300},\n",
    "         'overflows_Mean':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Overflow counter for #eTx from mean data',\n",
    "                      'nDec':0,\n",
    "                      'zMax':40000},\n",
    "         'overflows_30percent':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Overflow counter for #eTx+30% from mean data',\n",
    "                      'nDec':0,\n",
    "                      'zMax':40000},\n",
    "         'overflows_assigned':{'Title':'Layer %i',\n",
    "                      'colorLabel':'Overflow counter for #eTx assigned from HGCal baseline',\n",
    "                      'nDec':0,\n",
    "                      'zMax':40000},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var in Labels:\n",
    "    print(var)\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "    count=1\n",
    "    for layer in [5,7,9]:\n",
    "        wedge = wedges.loc[layer]\n",
    "        #fig, ax = plt.subplots()\n",
    "        plt.subplot(1, 3, count)\n",
    "        ax=plt.gca()\n",
    "        patches = []\n",
    "        for w in wedge.index:\n",
    "            patches.append(mpatches.RegularPolygon((wedge.loc[w].x,wedge.loc[w].y),6, .95))\n",
    "        df = fullData\n",
    "        extra = \"ttbar\"\n",
    "        data = df.loc[layer,var].values.flatten()\n",
    "        waferCollection = PatchCollection(patches,cmap=matplotlib.cm.coolwarm)\n",
    "        waferCollection.set_array(data)\n",
    "        waferCollection.set_clim([0,Labels[var]['zMax']])\n",
    "        ax.add_collection(waferCollection)\n",
    "        plt.axis([0,16,-1,15])\n",
    "        plt.rcParams[\"figure.autolayout\"] = True\n",
    "        # ax.set_xticklabels([])\n",
    "        # ax.set_yticklabels([]);\n",
    "        cbar = plt.colorbar(waferCollection)\n",
    "        cbar.set_label(Labels[var]['colorLabel'],fontsize=14)\n",
    "\n",
    "        wedge['data'] = data\n",
    "        plt.title(Labels[var]['Title']%layer,fontsize=14)\n",
    "        for x,y,d in wedge[['x','y','data']].values:\n",
    "        #     s = data[i]\n",
    "            text = f'%.{Labels[var][\"nDec\"]}f'%d\n",
    "            if len(str(d))>4:\n",
    "                text = \"{:.2e}\".format(d)\n",
    "                text = \"%s\\ne%s\"%(text.split(\"e\")[0], text.split(\"e\")[1])\n",
    "            plt.text(x,y,text,fontsize=9,horizontalalignment='center',verticalalignment='center')         \n",
    "\n",
    "        #fig.savefig(f'Plots/{var}_layer{layer}{extra}.png')\n",
    "        count+=1\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
