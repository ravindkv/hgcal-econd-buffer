{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "sys.path.insert(0, \"%s/hgcalEnv/lib/python3.6/site-packages/\"%os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of number of link that are assigned\n",
    "linkSummary = pd.read_csv('geomInfo/ModuleLinkSummary.csv')\n",
    "\n",
    "# six cassettes are put together to form one layer. Currently, we look at only 0th cassete of a few layers (5,7,9)\n",
    "linkSummary = linkSummary[(linkSummary.Cassette==0) & (linkSummary.Layer>=5) & (linkSummary.Layer<=9)]\n",
    "\n",
    "# The (ModU, modV) is the (U, V) coordinate of a module (=wafer=econ) within a layer\n",
    "linkSummary.set_index(['Layer','ModU','ModV'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data from csv files.  This is used to extract average data sizes\n",
    "#daq_Data = pd.concat([pd.read_csv(f'Data/ttbar_copy_new.csv') for i in range(16)])\n",
    "daq_Data = pd.read_csv('dataZS_merged.csv')\n",
    "'''\n",
    "The daq_Data consist of the entries after applying ZS corresponding to different cells \n",
    "(a layer has many wafers, a wafer has many cells). The description about the each of columns\n",
    "(c1): It is the index of df\n",
    "(c2 = entry): those events which passed the ZS\n",
    "(c3 = layer): layer number (from 5 to 9)\n",
    "(c4 = waferu): U coordinate of the wafer\n",
    "(c5 = waferv): V coordinate of the wafer\n",
    "\n",
    "(c6 = HDM): high density module: One of the 8-inch wafers/modules with 432 cells \n",
    "(compared to the LDM, or low-density module, which has 192 cells)\n",
    "the type 0 are 120 micron thick and HDM and closest to beam pipe,\n",
    "type 1 is 200 microns thick LDM modules, and a little further out\n",
    "type 2 are 300 micron LDM modules, and furthest from beam pipe in eta\n",
    "If HDM is True then it correspond to type 0 else 1 or 2\n",
    "\n",
    "(c7 = occ): Occupancy: Each wafer has 3-6 eLink, each eLink has up to 37 channels, \n",
    "we’ve applied the zero suppression, so any channel below the threshold is removed, \n",
    "so the count is just counting how many cells on a given eLink on a given wafer pass the ZS\n",
    "\n",
    "(c8 = eRxPacket_Words): It is the size of the packet in terms of number of words (1 word is of 32 bit).\n",
    "It is calculated as int(Bits/32+1) + 2, where Bits = 16  + 8* (charge_BX1 + toa_BX2)\n",
    "\n",
    "(c9  = NonEmptyLinks): We have total 6 (12) eLinks for HDM(LDM). \n",
    "\n",
    "(c10 = EmptyLinks): The rest eLinks\n",
    "\n",
    "(c11 = TotalWords): evt_headerWords (=2) + eRxPacket_Words + EmptyLinks + evt_trailerWords (=2)\n",
    "\n",
    "''' \n",
    "#daq_Data\n",
    "#get list of wedges, and assign x and y positions for drawing maps\n",
    "wedges = daq_Data.groupby(['layer','waferu','waferv']).any()[['HDM']].reset_index()\n",
    "wedges['y'] = wedges.waferv\n",
    "wedges['x'] = 0\n",
    "#QQQQ: why 2+v-2*u?\n",
    "wedges.loc[:,'x'] = (2+wedges.y-2*wedges.waferu)\n",
    "#QQQQ: why rescale y and x?\n",
    "wedges.y *= 1.5\n",
    "wedges.x *= -3**.5/2\n",
    "wedges.set_index(['layer','waferu','waferv'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to look through output logs of condor jobs to extract and accumulate the results across several runs\n",
    "# if you just ran interactivel, need to just get the info on the overflows, max size, etc into a dataframe.\n",
    "\n",
    "def getDF(inputDF, LogDir=\"log\", LogName=None,Nstart=0,N=100):\n",
    "    #QQQQ: Why mean?\n",
    "    fullData = inputDF.groupby(['layer','waferu','waferv']).mean()\n",
    "    \n",
    "    #linkSummary has only 153 rows which means the last 10 rows will be assigned Nan. \n",
    "    #QQQQ: Why linkSummary has only 153 rows?\n",
    "    fullData['eTx_assigned'] = linkSummary.ECOND_eTX\n",
    "    \n",
    "    #Replace Nan by 1\n",
    "    fullData.eTx_assigned = fullData.eTx_assigned.fillna(1).astype(int)\n",
    "    \n",
    "    #The numpy.ceil() is a mathematical function that returns the ceil of the elements of array. \n",
    "    #The ceil of the scalar x is the smallest integer i, such that i >= x\n",
    "    #QQQQ: why divide by 53.3333? One eTx can process 53.3333 Words of data?\n",
    "    fullData['eTx_Mean'] = np.ceil((fullData.TotalWords/53.3333))\n",
    "    fullData['eTx_30percent'] = np.ceil((fullData.TotalWords/53.3333)*1.3).astype(int)\n",
    "    fullData['eTx_30percent_actual'] = fullData['eTx_30percent']/(fullData.TotalWords/53.3333)\n",
    "    '''\n",
    "    Every condor output has information for 6 econs (they have different # eLinks)\n",
    "    We collect information from ALL condor outputs for ALL econs in a 2D (163,6) array\n",
    "\n",
    "    overflows: An econ with few number of eLink is overflown for a few thousands times in \n",
    "    few million BX which means for few billion BXs (many condor outputs) the overflows should be added\n",
    "\n",
    "    maxSize: Among all condor outputs, it is the maximum buffer size. Which means it is NOT additive\n",
    "\n",
    "    L1As issued: How many times an L1A is issued for a given number of BXs. Which means it is additive\n",
    "\n",
    "    '''\n",
    "    if not LogName is None:\n",
    "        data_overflow = []\n",
    "        data_maxSize = []\n",
    "        L1As_issued=0\n",
    "        bHist = []\n",
    "        #Get the 0th element of the list from 0th condor file\n",
    "        fileName = f'condor_buffer/tmpSub/{LogDir}/{LogName}_{Nstart}.stdout'\n",
    "        with open(fileName,'r') as _file:\n",
    "            # we loop over all lines of the condor output and extract\n",
    "            for line in _file:\n",
    "                if 'overflows= ' in line:\n",
    "                    #overflows= [...]\n",
    "                    data_overflow.append(eval(line[10:]))\n",
    "                if 'maxSize= ' in line:\n",
    "                    #maxSize= [...]\n",
    "                    data_maxSize.append(eval(line[8:]))\n",
    "                if 'L1As issued' in line:\n",
    "                    #749401 L1As issued\n",
    "                    L1As_issued += int(line.split()[0])\n",
    "                if 'sizeHist= ' in line:\n",
    "                    bHist.append(eval(line[9:]))\n",
    "        #2D array            \n",
    "        data_overflow=np.array(data_overflow)\n",
    "        data_maxSize=np.array(data_maxSize)\n",
    "        buff_Hist = np.array(bHist)\n",
    "\n",
    "        for i_file in range(Nstart+1,Nstart+N):\n",
    "            fileName = f'condor_buffer/tmpSub/{LogDir}/{LogName}_{i_file}.stdout'\n",
    "            bHist = []\n",
    "            with open(fileName,'r') as _file:\n",
    "                for line in _file:\n",
    "                    if 'eTx' in line:\n",
    "                        #1 eTx\n",
    "                        i = int(line.split()[0])-1\n",
    "                    if 'overflows= ' in line:\n",
    "                        overflow=np.array(eval(line[10:]))\n",
    "                        overflow[overflow<0] = 99999999\n",
    "                        data_overflow[i] += overflow\n",
    "                    if 'maxSize= ' in line:\n",
    "                        maxSize=np.array(eval(line[8:]))\n",
    "                        data_maxSize[i] = np.maximum(data_maxSize[i], maxSize)\n",
    "                    if 'L1As issued' in line:\n",
    "                        L1As_issued += int(line.split()[0])\n",
    "                    if 'sizeHist= ' in line:\n",
    "                        bHist.append(eval(line[9:]))\n",
    "            buff_Hist += np.array(bHist)\n",
    "        \n",
    "        '''\n",
    "        The idea is to check how many eLinks are needed for a given wafer in order to avoid overflow.\n",
    "        For example, the wafer closer to beam axis need more eLinks and vice versa. In this way we can\n",
    "        efficiantly allocate different number of eLinks to different wafers\n",
    "        '''\n",
    "        #transpose (163 col, 6 rows) to (6 cols, 163 rows)\n",
    "        #In every row look at zero (True==0) and non-zero entries\n",
    "        #Multiply the respective entry by array([1, 2, 3, 4, 5, 6])\n",
    "        x = ((data_overflow.transpose()==0)*np.arange(1,7))\n",
    "\n",
    "        #change all zero entries to 99 (we can choose any large value)\n",
    "        x[x==0]=99\n",
    "        \n",
    "        #for every row, get the minimum value (out of 6 econs, pick the one which has minimum eLink)\n",
    "        minLinks = x.min(axis=1)\n",
    "        fullData['min_eTx'] = minLinks\n",
    "        nLinks = minLinks\n",
    "        #print(data_overflow.transpose())\n",
    "        \n",
    "        #Get the maximum size of the buffer of the corresponding econ with minLinks\n",
    "        maxSize = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize'] = maxSize    \n",
    "\n",
    "        \n",
    "        nLinks = fullData.eTx_Mean.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][int(nLinks[i])-1])\n",
    "            overflows.append(data_overflow.transpose()[i][int(nLinks[i])-1])\n",
    "        fullData['maxSize_Mean'] = maxSize\n",
    "        fullData['overflows_Mean'] = overflows\n",
    "        \n",
    "        \n",
    "        nLinks = fullData.eTx_assigned.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_assigned'] = maxSize\n",
    "        fullData['overflows_assigned'] = overflows\n",
    "        \n",
    "\n",
    "        nLinks = fullData.eTx_30percent.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_30percent'] = maxSize\n",
    "        fullData['overflows_30percent'] = overflows\n",
    "        #print(\"fullData = \", fullData)\n",
    "        #print(\"L1As_issued = \", L1As_issued)\n",
    "        #print(\"data_overflow = \", data_overflow)\n",
    "        #print(\"data_maxSize = \", data_maxSize)\n",
    "    #return fullData, L1As_issued, data_overflow, data_maxSize, buff_Hist\n",
    "    #print(\"buff_Hist\", buff_Hist)\n",
    "    return fullData, L1As_issued, buff_Hist, data_overflow, data_maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBuffHist(buffHist):\n",
    "    colList = [\"c\", \"b\", \"g\", \"r\",\"m\",\"y\"]\n",
    "    xArray = []\n",
    "    for i in range(1536*2):\n",
    "        xArray.append(i)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    count = 1\n",
    "    plt.subplots(figsize=(15, 10))\n",
    "    #for h in range(len(buffHist)):\n",
    "    for h in range(5):\n",
    "        #print(count)\n",
    "        plt.subplot(3, 5, count)\n",
    "        for eTx in range(len(buffHist)):\n",
    "            #plt.plot( xArray, buffHist[eTx][h], label=\"eTx=%i\"%(eTx+1))\n",
    "            plt.hist(xArray, bins=50, weights=buffHist[eTx][h], edgecolor=colList[eTx], label=\"eTx=%i\"%(eTx+1), histtype='step', linewidth=2)\n",
    "            plt.title(\"wafer=%s\"%str(wedges.index[h]))\n",
    "            #plt.xlabel(\"Buffer size (32-bit words)\", size=14)\n",
    "            #plt.xlabel(\"Buffer size\", size=14)\n",
    "            plt.legend(loc='upper center')\n",
    "            plt.yscale('log')\n",
    "        count+=1\n",
    "    plt.show()\n",
    "\n",
    "def plotSize(sizeList, linkList, buffHist, plotTit, m):\n",
    "    xArray = []\n",
    "    for i in range(1536*2):\n",
    "        xArray.append(i)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.subplots(figsize=(25, 10))\n",
    "    #indices of maximum buffer size\n",
    "    #Return the index of original list after sorting it\n",
    "    index5 = sorted(range(len(m[0:53])), key=lambda k: m[0:53][k])\n",
    "    index7 = sorted(range(len(m[53:108])), key=lambda k: m[53:108][k])\n",
    "    index9 = sorted(range(len(m[108:163])), key=lambda k: m[108:163][k])\n",
    "    \n",
    "    layers = {}\n",
    "    layers[\"layer5\"] = [index5[-1], index5[-2], index5[0]]\n",
    "    layers[\"layer7\"] = [53+index7[-1], 53+index7[-2], 53+index7[0]]\n",
    "    layers[\"layer9\"] = [108+index9[-1], 108+index9[-2], 108+index9[0]]\n",
    "    count = 1\n",
    "    yMin  = 1\n",
    "    for layer in layers.keys():\n",
    "        plt.subplot(3, 5, count)\n",
    "        for wafer in layers[layer]:\n",
    "            hist = buffHist[int(linkList[wafer])-1][wafer]\n",
    "            lab = \"ℓ, wu, wv = %s; eTx = %s, max= %s\"%(wedges.index[wafer], int(linkList[wafer]), sizeList[wafer])\n",
    "            plt.hist(xArray, bins=50, weights=hist, label=lab, histtype='step', linewidth=3)\n",
    "            plt.xlabel(\"Buffer size (32-bit words)\", size=14)\n",
    "            plt.ylabel(\"BX\", size=14)\n",
    "            plt.ylim(yMin, 10e12)\n",
    "            plt.legend(loc='upper center')\n",
    "            plt.yscale('log')\n",
    "        count+=1\n",
    "        plt.title(plotTit)\n",
    "        plt.axvline(x=1536, color=\"r\", linestyle='--')\n",
    "        plt.axvline(x=3072, color=\"r\", linestyle='--')\n",
    "        plt.text(1536+50, 10e4*yMin, \"128-word depth\", rotation=90, verticalalignment='center')\n",
    "        plt.text(3072+50, 10e4*yMin, \"256-word depth\", rotation=90, verticalalignment='center')\n",
    "    plt.show()\n",
    "    \n",
    "def plotMaxSize(xList, yList, xTit, yTit, plotTit, drawLine=False): \n",
    "    ETx = np.array(xList)\n",
    "    l1_ETx = ETx[0:53]\n",
    "    l2_ETx = ETx[53:53+55]\n",
    "    l3_ETx = ETx[53+55:53+55+55]\n",
    "    l1_overflow = []\n",
    "    l2_overflow = []\n",
    "    l3_overflow = []\n",
    "    for i in np.arange(len(l1_ETx)):\n",
    "        eTx = int(l1_ETx[i])\n",
    "        l1_overflow.append(yList.transpose()[i][eTx-1])\n",
    "\n",
    "    for i in np.arange(len(l2_ETx)):\n",
    "        eTx = int(l2_ETx[i])\n",
    "        l2_overflow.append(yList.transpose()[i+53][eTx-1])\n",
    "\n",
    "    for i in np.arange(len(l3_ETx)):\n",
    "        eTx = int(l3_ETx[i])\n",
    "        l3_overflow.append(yList.transpose()[i+53+55][eTx-1])\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(l1_overflow, bins=70,  label=\"ℓ = 5 (53 wafers)     \", histtype='step', linewidth=3, edgecolor='r')\n",
    "    plt.hist(l2_overflow, bins=70,  label=\"ℓ = 7 (55 wafers)     \", histtype='step', linewidth=3, edgecolor='g')\n",
    "    plt.hist(l3_overflow, bins=70,  label=\"ℓ = 9 (55 wafers)     \", histtype='step', linewidth=3, edgecolor='b')\n",
    "    plt.xlabel(xTit, size=14)\n",
    "    plt.ylabel(yTit, size=14)\n",
    "    plt.ylim(0.1, 60)\n",
    "    plt.title(plotTit)\n",
    "    plt.legend(loc=\"upper right\", frameon=False)\n",
    "    plt.yscale('log')\n",
    "    if drawLine:\n",
    "        plt.axvline(x=1536, color=\"r\", linestyle='--')\n",
    "        plt.axvline(x=3072, color=\"r\", linestyle='--')\n",
    "        plt.text(1536+50, 5, \"128-word depth\", rotation=90, verticalalignment='center')\n",
    "        plt.text(3072+50, 5, \"256-word depth\", rotation=90, verticalalignment='center')\n",
    "        \n",
    "\n",
    "def plotTotalWords(sizeList):   \n",
    "    branchList = ['entry','layer','waferu','waferv','HDM','TotalWords', \"TotalWords_NZS\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.subplots(figsize=(15, 10))\n",
    "    group = daq_Data.reset_index().groupby(['layer', 'waferu','waferv', 'HDM'])\n",
    "    histDF = group['TotalWords'].apply(list).reset_index()\n",
    "    histDF2 = group['TotalWords_NZS'].apply(list).reset_index()\n",
    "    count = 1\n",
    "    #Return the index of original list after sorting it\n",
    "    index5 = sorted(range(len(sizeList[0:53])), key=lambda k: sizeList[0:53][k])\n",
    "    index7 = sorted(range(len(sizeList[53:108])), key=lambda k: sizeList[53:108][k])\n",
    "    index9 = sorted(range(len(sizeList[108:163])), key=lambda k: sizeList[108:163][k])\n",
    "    \n",
    "    layers = {}\n",
    "    layers[\"layer5\"] = [index5[-1], index5[-2], index5[0]]\n",
    "    layers[\"layer7\"] = [53+index7[-1], 53+index7[-2], 53+index7[0]]\n",
    "    layers[\"layer9\"] = [108+index9[-1], 108+index9[-2], 108+index9[0]]\n",
    "    for layer in layers.keys():\n",
    "        for wafer in layers[layer]:\n",
    "            #print(count)\n",
    "            #luv = random.choice(wedges.index)\n",
    "            luv = wedges.index[wafer]\n",
    "            print(luv)\n",
    "            plt.subplot(3, 5, count)\n",
    "            sel = (histDF.layer==luv[0]) & (histDF.waferu==luv[1]) & (histDF.waferv==luv[2])\n",
    "            histList = histDF.loc[sel, 'TotalWords'].to_list()\n",
    "            histList_NZS = histDF2.loc[sel, 'TotalWords_NZS'].to_list()\n",
    "            #print(histList)\n",
    "            #print(histList_NZS)\n",
    "            plt.hist(histList, label=\"ZS\", histtype='step', linewidth=2)\n",
    "            plt.hist(histList_NZS, label=\"NZS\", histtype='step', linewidth=2)\n",
    "            plt.title(\"(layer, wu, wv)=%s\"%str(luv))\n",
    "            plt.xlabel(\"Total 32-bit words\", size=14)\n",
    "            plt.ylabel(\"Events\", size=14)\n",
    "            plt.legend(loc='upper center')\n",
    "            #plt.yscale('log')\n",
    "            count+=1\n",
    "    plt.show()\n",
    "    \n",
    "def plotOverFlow(OF):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(OF[0], bins=70,  label=\"1 eTx\", fill=False, linewidth=3, edgecolor='c')\n",
    "    plt.hist(OF[1], bins=70,  label=\"2 eTx\", fill=False, linewidth=3, edgecolor='b')\n",
    "    plt.hist(OF[2], bins=70,  label=\"3 eTx\", fill=False, linewidth=3, edgecolor='g')\n",
    "    plt.hist(OF[3], bins=70,  label=\"4 eTx\", fill=False, linewidth=3, edgecolor='r')\n",
    "    plt.hist(OF[4], bins=70,  label=\"5 eTx\", fill=False, linewidth=3, edgecolor='m')\n",
    "    plt.hist(OF[5], bins=70,  label=\"6 eTx\", fill=False, linewidth=3, edgecolor='y')\n",
    "    plt.xlabel(\"Overflows\", size=14)\n",
    "    plt.ylabel(\"Number of Wafers\", size=14)\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Overflows for different numbers of eTx\")\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    \n",
    "def plot2D(fullData):\n",
    "    #dictionaly of the labels for different types of plots\n",
    "    Labels ={'occ':{'Title':'Layer %i',\n",
    "                    'colorLabel':'Average cell occupancy above ZS',\n",
    "                    'nDec':1,\n",
    "                    'zMax':260},\n",
    "             'TotalWords':{'Title':'Layer %i',\n",
    "                          'colorLabel':'Average data size (32b words) after L1A',\n",
    "                          'nDec':1,\n",
    "                          'zMax':200},\n",
    "             'EmptyLinks':{'Title':'Layer %i',\n",
    "                          'colorLabel':'Average # of empty eRx packets',\n",
    "                          'nDec':1,\n",
    "                          'zMax':6},\n",
    "             'min_eTx':{'Title':'Layer %i',\n",
    "                          'colorLabel':'Minimum number of eTx with 0 overflow',\n",
    "                          'nDec':0,\n",
    "                          'zMax':6},\n",
    "             'maxSize':{'Title':'Layer %i',\n",
    "                          'colorLabel':'Max buffer size (MBS) with 0 overflow',\n",
    "                          'nDec':0,\n",
    "                          'zMax':100},\n",
    "             'eTx_Mean':{'Title':'Layer %i',\n",
    "                          'colorLabel':'#eTx from mean data',\n",
    "                          'nDec':2,\n",
    "                          'zMax':6},\n",
    "             'eTx_30percent':{'Title':'Layer %i',\n",
    "                          'colorLabel':'#eTx+30% from mean data',\n",
    "                          'nDec':0,\n",
    "                          'zMax':6},\n",
    "             'eTx_30percent_actual':{'Title':'Layer %i',\n",
    "                          'colorLabel':'actual overhead for #eTx+30% assignment',\n",
    "                          'nDec':0,\n",
    "                          'zMax':6},             \n",
    "             'eTx_assigned':{'Title':'Layer %i',\n",
    "                          'colorLabel':'#eTx assigned from HGCal baseline',\n",
    "                          'nDec':0,\n",
    "                          'zMax':6},\n",
    "             'maxSize_Mean':{'Title':'Layer %i',\n",
    "                          'colorLabel':'MBS for #eTx from mean data',\n",
    "                          'nDec':0,\n",
    "                          'zMax':100},\n",
    "             'maxSize_30percent':{'Title':'Layer %i',\n",
    "                          'colorLabel':'MBS for #eTx+30% from mean data',\n",
    "                          'nDec':0,\n",
    "                          'zMax':100},\n",
    "             'maxSize_assigned':{'Title':'Layer %i',\n",
    "                          'colorLabel':'MBS for #eTx from HGCal baseline',\n",
    "                          'nDec':0,\n",
    "                          'zMax':100},\n",
    "             'overflows_Mean':{'Title':'Layer %i',\n",
    "                          'colorLabel':'OC for #eTx from mean data',\n",
    "                          'nDec':0,\n",
    "                          'zMax':40000},\n",
    "             'overflows_30percent':{'Title':'Layer %i',\n",
    "                          'colorLabel':'OC for #eTx+30% from mean data',\n",
    "                          'nDec':0,\n",
    "                          'zMax':40000},\n",
    "             'overflows_assigned':{'Title':'Layer %i',\n",
    "                          'colorLabel':'OC for #eTx from HGCal baseline',\n",
    "                          'nDec':0,\n",
    "                          'zMax':40000},\n",
    "            }\n",
    "    \n",
    "    #for var in Labels:\n",
    "    #for var in [\"eTx_Mean\", \"eTx_30percent\",  \"eTx_assigned\", \"eTx_30percent_actual\"]:\n",
    "    for var in [\"eTx_assigned\", \"maxSize_assigned\", \"overflows_assigned\", \"eTx_Mean\", \"maxSize_Mean\", \"overflows_Mean\", \"eTx_30percent\", \"maxSize_30percent\", \"overflows_30percent\", \"eTx_30percent_actual\"]:    \n",
    "        print(var)\n",
    "        plt.subplots(figsize=(15, 5))\n",
    "        count=1\n",
    "        for layer in [5,7,9]:\n",
    "            wedge = wedges.loc[layer]\n",
    "            #fig, ax = plt.subplots()\n",
    "            plt.subplot(1, 3, count)\n",
    "            ax=plt.gca()\n",
    "            patches = []\n",
    "            for w in wedge.index:\n",
    "                patches.append(mpatches.RegularPolygon((wedge.loc[w].x,wedge.loc[w].y),6, .95))\n",
    "            extra = \"ttbar\"\n",
    "            data = fullData.loc[layer,var].values.flatten()\n",
    "            if 'maxSize' in var:\n",
    "                data = data*100/3072\n",
    "            waferCollection = PatchCollection(patches,cmap=matplotlib.cm.coolwarm)\n",
    "            waferCollection.set_array(data)\n",
    "            waferCollection.set_clim([0,Labels[var]['zMax']])\n",
    "            ax.add_collection(waferCollection)\n",
    "            plt.axis([0,16,-1,15])\n",
    "            plt.rcParams[\"figure.autolayout\"] = True\n",
    "            # ax.set_xticklabels([])\n",
    "            # ax.set_yticklabels([]);\n",
    "            cbar = plt.colorbar(waferCollection)\n",
    "            cbar.set_label(Labels[var]['colorLabel'],fontsize=14)\n",
    "\n",
    "            wedge['data'] = data\n",
    "            plt.title(Labels[var]['Title']%layer,fontsize=14)\n",
    "            for x,y,d in wedge[['x','y','data']].values:\n",
    "            #     s = data[i]\n",
    "                text = f'%.{Labels[var][\"nDec\"]}f'%d\n",
    "                if len(str(d))>4:\n",
    "                    text = \"{:.2e}\".format(d)\n",
    "                    text = \"%s\\ne%s\"%(text.split(\"e\")[0], text.split(\"e\")[1])\n",
    "                if \"maxSize\" in var:\n",
    "                    per = round(d,1)\n",
    "                    text = \"%s\\n%s\"%(per, \"%\")\n",
    "                if \"actual\" in var:\n",
    "                    per = round(d,2)\n",
    "                    text = \"%s\"%(per)  \n",
    "                plt.text(x,y,text,fontsize=9,horizontalalignment='center',verticalalignment='center')         \n",
    "\n",
    "            #fig.savefig(f'Plots/{var}_layer{layer}{extra}.png')\n",
    "            count+=1\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData, L1As, buffHist, OF, MS = getDF(daq_Data, 'log_0', 'bufferSim__74754635', 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData2, L1As2, buffHist2, OF2, MS2 = getDF(daq_Data, 'log_100', 'bufferSim__74754636', 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullData3, L1As3, buffHist3, OF3, MS3 = getDF(daq_Data, 'log_1000', 'bufferSim__74754637', 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotAll(fullData, L1As, buffHist, OF, MS):\n",
    "    eTxMean = \"#eTx from mean data\"\n",
    "    eTx30p  = \"#eTx+30% from mean data\"\n",
    "    eTxHGCal= \"#eTx from HGCal baseline\"\n",
    "    yTit = \"Number of Wafers\"\n",
    "    xTit = \"Number of times buffer has Overflown\"\n",
    "    \n",
    "    #plotMaxSize(fullData.eTx_Mean.tolist(), OF, xTit, yTit, eTxMean)\n",
    "    #plotMaxSize(fullData.eTx_30percent.tolist(), OF, xTit, yTit, eTx30p)\n",
    "    #plotMaxSize(fullData.eTx_assigned.tolist(), OF, xTit, yTit, eTxHGCal)\n",
    "\n",
    "    yTit = \"Number of Wafers\"\n",
    "    xTit = \"Max buffer size (32-bit words)\"\n",
    "    plotMaxSize(fullData.eTx_Mean.tolist(), MS, xTit, yTit, eTxMean, True)\n",
    "    plotMaxSize(fullData.eTx_30percent.tolist(), MS, xTit, yTit, eTx30p, True)\n",
    "    plotMaxSize(fullData.eTx_assigned.tolist(), MS, xTit, yTit, eTxHGCal, True)\n",
    "    #To pick modules based on maxSize from 30%+mean data\n",
    "    m = fullData.maxSize_30percent.values\n",
    "    plotSize(fullData.maxSize_Mean.values, fullData.eTx_Mean.values, buffHist, eTxMean, m)\n",
    "    plotSize(fullData.maxSize_30percent.values, fullData.eTx_30percent.values, buffHist, eTx30p, m)\n",
    "    plotSize(fullData.maxSize_assigned.values, fullData.eTx_assigned.values, buffHist, eTxHGCal, m)\n",
    "\n",
    "    #plotBuffHist(buffHist)\n",
    "    plot2D(fullData)\n",
    "    plotTotalWords(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotAll(fullData, L1As, buffHist, OF, MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAll(fullData2, L1As2, buffHist2, OF2, MS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
